[
  {
    "trial_number": 0,
    "params": {
      "hidden_layer_sizes": [
        140
      ],
      "activation": "tanh",
      "alpha": 0.008507940064713367,
      "learning_rate": "adaptive",
      "max_iter": 613
    },
    "score": 0.1419925810363601,
    "time": 51.60959458351135
  },
  {
    "trial_number": 1,
    "params": {
      "hidden_layer_sizes": [
        114
      ],
      "activation": "logistic",
      "alpha": 0.02443893868413922,
      "learning_rate": "invscaling",
      "max_iter": 342
    },
    "score": 0.25404865115847913,
    "time": 24.22364592552185
  },
  {
    "trial_number": 2,
    "params": {
      "hidden_layer_sizes": [
        29,
        41
      ],
      "activation": "logistic",
      "alpha": 0.033965443605815535,
      "learning_rate": "constant",
      "max_iter": 573
    },
    "score": 0.20419509791248563,
    "time": 48.0588014125824
  },
  {
    "trial_number": 3,
    "params": {
      "hidden_layer_sizes": [
        46
      ],
      "activation": "logistic",
      "alpha": 0.00040695335493999053,
      "learning_rate": "adaptive",
      "max_iter": 320
    },
    "score": 0.18227179747075067,
    "time": 26.241121530532837
  },
  {
    "trial_number": 4,
    "params": {
      "hidden_layer_sizes": [
        120,
        156,
        129
      ],
      "activation": "relu",
      "alpha": 1.7539816393453883e-05,
      "learning_rate": "constant",
      "max_iter": 531
    },
    "score": 0.16465461302755355,
    "time": 33.104748249053955
  },
  {
    "trial_number": 5,
    "params": {
      "hidden_layer_sizes": [
        89
      ],
      "activation": "relu",
      "alpha": 0.04611981777760185,
      "learning_rate": "invscaling",
      "max_iter": 982
    },
    "score": 0.1757362912053106,
    "time": 36.05464243888855
  },
  {
    "trial_number": 6,
    "params": {
      "hidden_layer_sizes": [
        186
      ],
      "activation": "tanh",
      "alpha": 1.4041021021130903e-05,
      "learning_rate": "invscaling",
      "max_iter": 902
    },
    "score": 0.15406778438976662,
    "time": 61.77102184295654
  },
  {
    "trial_number": 7,
    "params": {
      "hidden_layer_sizes": [
        109
      ],
      "activation": "relu",
      "alpha": 0.0038174173972190147,
      "learning_rate": "constant",
      "max_iter": 802
    },
    "score": 0.17119499081455822,
    "time": 38.25968360900879
  },
  {
    "trial_number": 8,
    "params": {
      "hidden_layer_sizes": [
        67,
        124
      ],
      "activation": "tanh",
      "alpha": 6.1016268142327623e-05,
      "learning_rate": "invscaling",
      "max_iter": 909
    },
    "score": 0.12002535164683832,
    "time": 39.57029628753662
  },
  {
    "trial_number": 9,
    "params": {
      "hidden_layer_sizes": [
        51,
        96,
        158
      ],
      "activation": "relu",
      "alpha": 0.00021184027768383673,
      "learning_rate": "adaptive",
      "max_iter": 771
    },
    "score": 0.15523591120229607,
    "time": 34.79923057556152
  },
  {
    "trial_number": 10,
    "params": {
      "hidden_layer_sizes": [
        166,
        194
      ],
      "activation": "logistic",
      "alpha": 0.0024452198706659467,
      "learning_rate": "invscaling",
      "max_iter": 243
    },
    "score": 0.15530319023006198,
    "time": 139.4385950565338
  },
  {
    "trial_number": 11,
    "params": {
      "hidden_layer_sizes": [
        13,
        31
      ],
      "activation": "logistic",
      "alpha": 0.08720251768534402,
      "learning_rate": "constant",
      "max_iter": 447
    },
    "score": 0.27345285308866196,
    "time": 11.49058723449707
  },
  {
    "trial_number": 12,
    "params": {
      "hidden_layer_sizes": [
        10,
        11
      ],
      "activation": "logistic",
      "alpha": 0.09902203805046628,
      "learning_rate": "constant",
      "max_iter": 411
    },
    "score": 0.2745233067044256,
    "time": 9.517374277114868
  },
  {
    "trial_number": 13,
    "params": {
      "hidden_layer_sizes": [
        13,
        12
      ],
      "activation": "logistic",
      "alpha": 0.08660834986045092,
      "learning_rate": "constant",
      "max_iter": 446
    },
    "score": 0.2727427937315924,
    "time": 10.60514211654663
  },
  {
    "trial_number": 14,
    "params": {
      "hidden_layer_sizes": [
        12,
        54,
        13
      ],
      "activation": "logistic",
      "alpha": 0.011433926036885977,
      "learning_rate": "constant",
      "max_iter": 441
    },
    "score": 0.18520649604999756,
    "time": 52.40639662742615
  },
  {
    "trial_number": 15,
    "params": {
      "hidden_layer_sizes": [
        69,
        13
      ],
      "activation": "logistic",
      "alpha": 0.0009233647883086637,
      "learning_rate": "constant",
      "max_iter": 416
    },
    "score": 0.12524232417480322,
    "time": 48.87327027320862
  },
  {
    "trial_number": 16,
    "params": {
      "hidden_layer_sizes": [
        31,
        63
      ],
      "activation": "logistic",
      "alpha": 0.09887207432166233,
      "learning_rate": "constant",
      "max_iter": 669
    },
    "score": 0.2736713213639317,
    "time": 9.90637493133545
  },
  {
    "trial_number": 17,
    "params": {
      "hidden_layer_sizes": [
        39,
        72
      ],
      "activation": "logistic",
      "alpha": 0.011302720599532107,
      "learning_rate": "constant",
      "max_iter": 684
    },
    "score": 0.13127969159435965,
    "time": 85.79326248168945
  },
  {
    "trial_number": 18,
    "params": {
      "hidden_layer_sizes": [
        79,
        81,
        38
      ],
      "activation": "logistic",
      "alpha": 0.003718324809013761,
      "learning_rate": "constant",
      "max_iter": 684
    },
    "score": 0.11865315246699382,
    "time": 77.69686079025269
  },
  {
    "trial_number": 19,
    "params": {
      "hidden_layer_sizes": [
        32,
        125,
        193
      ],
      "activation": "tanh",
      "alpha": 0.022569611761484958,
      "learning_rate": "constant",
      "max_iter": 231
    },
    "score": 0.09949384020102617,
    "time": 101.16884875297546
  }
]