[
  {
    "trial_number": 0,
    "params": {
      "hidden_layer_sizes": [
        23,
        74,
        128
      ],
      "activation": "relu",
      "alpha": 0.0009630310889379129,
      "learning_rate": "invscaling",
      "max_iter": 834
    },
    "score": 0.0755568724450914,
    "time": 73.68831467628479
  },
  {
    "trial_number": 1,
    "params": {
      "hidden_layer_sizes": [
        185,
        192
      ],
      "activation": "tanh",
      "alpha": 1.0704155004319111e-05,
      "learning_rate": "adaptive",
      "max_iter": 544
    },
    "score": 0.07051472160908412,
    "time": 215.61072063446045
  },
  {
    "trial_number": 2,
    "params": {
      "hidden_layer_sizes": [
        118
      ],
      "activation": "relu",
      "alpha": 0.0003908555040165838,
      "learning_rate": "constant",
      "max_iter": 375
    },
    "score": 0.08670018861757034,
    "time": 38.769965171813965
  },
  {
    "trial_number": 3,
    "params": {
      "hidden_layer_sizes": [
        144
      ],
      "activation": "logistic",
      "alpha": 0.0006849886977888291,
      "learning_rate": "constant",
      "max_iter": 225
    },
    "score": 0.09347990582059658,
    "time": 4.946686506271362
  },
  {
    "trial_number": 4,
    "params": {
      "hidden_layer_sizes": [
        80,
        121
      ],
      "activation": "relu",
      "alpha": 0.0005393290804327099,
      "learning_rate": "invscaling",
      "max_iter": 894
    },
    "score": 0.07506198813260086,
    "time": 78.5409984588623
  },
  {
    "trial_number": 5,
    "params": {
      "hidden_layer_sizes": [
        37,
        37
      ],
      "activation": "tanh",
      "alpha": 0.019590968463540144,
      "learning_rate": "invscaling",
      "max_iter": 433
    },
    "score": 0.08067929879271414,
    "time": 47.10534977912903
  },
  {
    "trial_number": 6,
    "params": {
      "hidden_layer_sizes": [
        120,
        42,
        72
      ],
      "activation": "relu",
      "alpha": 3.219643101634408e-05,
      "learning_rate": "constant",
      "max_iter": 577
    },
    "score": 0.0701301013991101,
    "time": 38.4876446723938
  },
  {
    "trial_number": 7,
    "params": {
      "hidden_layer_sizes": [
        87,
        189,
        200
      ],
      "activation": "relu",
      "alpha": 6.125011931194383e-05,
      "learning_rate": "adaptive",
      "max_iter": 265
    },
    "score": 0.06739934825410214,
    "time": 64.03119540214539
  },
  {
    "trial_number": 8,
    "params": {
      "hidden_layer_sizes": [
        139,
        183
      ],
      "activation": "relu",
      "alpha": 9.757768060078851e-05,
      "learning_rate": "adaptive",
      "max_iter": 893
    },
    "score": 0.07029426226916836,
    "time": 94.36923623085022
  },
  {
    "trial_number": 9,
    "params": {
      "hidden_layer_sizes": [
        49,
        136,
        56
      ],
      "activation": "tanh",
      "alpha": 9.998417287612189e-05,
      "learning_rate": "constant",
      "max_iter": 828
    },
    "score": 0.0634126637228161,
    "time": 107.78314924240112
  },
  {
    "trial_number": 10,
    "params": {
      "hidden_layer_sizes": [
        176
      ],
      "activation": "logistic",
      "alpha": 0.01163371917698216,
      "learning_rate": "constant",
      "max_iter": 200
    },
    "score": 0.09274777259277991,
    "time": 5.308016777038574
  },
  {
    "trial_number": 11,
    "params": {
      "hidden_layer_sizes": [
        176
      ],
      "activation": "logistic",
      "alpha": 0.009285582112924632,
      "learning_rate": "constant",
      "max_iter": 213
    },
    "score": 0.09291731406789874,
    "time": 5.317452907562256
  },
  {
    "trial_number": 12,
    "params": {
      "hidden_layer_sizes": [
        158
      ],
      "activation": "logistic",
      "alpha": 0.004968551888633742,
      "learning_rate": "constant",
      "max_iter": 332
    },
    "score": 0.09482179355372902,
    "time": 6.343836069107056
  },
  {
    "trial_number": 13,
    "params": {
      "hidden_layer_sizes": [
        145
      ],
      "activation": "logistic",
      "alpha": 0.0034499732941717398,
      "learning_rate": "constant",
      "max_iter": 374
    },
    "score": 0.09220533910119241,
    "time": 4.542187929153442
  },
  {
    "trial_number": 14,
    "params": {
      "hidden_layer_sizes": [
        155
      ],
      "activation": "logistic",
      "alpha": 0.06882884617763392,
      "learning_rate": "constant",
      "max_iter": 663
    },
    "score": 0.0894131774626434,
    "time": 3.7532460689544678
  },
  {
    "trial_number": 15,
    "params": {
      "hidden_layer_sizes": [
        97
      ],
      "activation": "logistic",
      "alpha": 0.0024161752773176077,
      "learning_rate": "constant",
      "max_iter": 320
    },
    "score": 0.09346048293791376,
    "time": 3.45607590675354
  },
  {
    "trial_number": 16,
    "params": {
      "hidden_layer_sizes": [
        197,
        84
      ],
      "activation": "logistic",
      "alpha": 0.002742627334293975,
      "learning_rate": "constant",
      "max_iter": 464
    },
    "score": 0.09200996753299082,
    "time": 14.746273517608643
  },
  {
    "trial_number": 17,
    "params": {
      "hidden_layer_sizes": [
        158
      ],
      "activation": "logistic",
      "alpha": 0.0992926884499494,
      "learning_rate": "constant",
      "max_iter": 709
    },
    "score": 0.08989203148608037,
    "time": 5.034125804901123
  },
  {
    "trial_number": 18,
    "params": {
      "hidden_layer_sizes": [
        120
      ],
      "activation": "logistic",
      "alpha": 0.00030170948105559363,
      "learning_rate": "invscaling",
      "max_iter": 300
    },
    "score": 0.0963558745163606,
    "time": 10.065729141235352
  },
  {
    "trial_number": 19,
    "params": {
      "hidden_layer_sizes": [
        61,
        11
      ],
      "activation": "logistic",
      "alpha": 0.0002681087758990693,
      "learning_rate": "invscaling",
      "max_iter": 504
    },
    "score": 0.09330654841934041,
    "time": 3.46954083442688
  }
]