# ğŸ§¬ ClassificaÃ§Ã£o de Genes-Alvo usando Dados Multi-Ã”micos

Este projeto implementa uma pipeline completa para classificaÃ§Ã£o de genes-alvo usando dados multi-Ã´micos (CNA, Gene Expression, Methylation, Mutation Frequency) com otimizaÃ§Ã£o automÃ¡tica de hiperparÃ¢metros usando Optuna.

## ğŸ“ Estrutura do Projeto

```
/tcc/artigo/
â”œâ”€â”€ ğŸ“‹ README.md              # DocumentaÃ§Ã£o completa do projeto
â”œâ”€â”€ ğŸš€ main.py               # Arquivo principal para experimentos
â”œâ”€â”€ âš™ï¸  processamento.py      # FunÃ§Ãµes de processamento de dados
â”œâ”€â”€ ğŸ§ª exemplo.py            # Exemplos de uso individual
â”œâ”€â”€ ğŸ”§ setup.py              # Script de configuraÃ§Ã£o automÃ¡tica
â”œâ”€â”€ ğŸ” test_environment.py   # Teste de ambiente e dependÃªncias
â””â”€â”€ ğŸ“ results/              # DiretÃ³rio para resultados organizados
```

## ğŸ“¦ Modelos Implementados

âœ… **7 modelos de classificaÃ§Ã£o com otimizaÃ§Ã£o Optuna:**

1. ğŸŒ³ **Decision Tree Classifier** - Ãrvore de decisÃ£o com otimizaÃ§Ã£o de profundidade e critÃ©rio
2. ğŸŒ² **Random Forest Classifier** - Ensemble de Ã¡rvores com otimizaÃ§Ã£o de estimadores e features
3. ğŸ“ˆ **Gradient Boosting Classifier** - Boosting gradiente com otimizaÃ§Ã£o de learning rate
4. ğŸ“Š **Histogram Gradient Boosting Classifier** - VersÃ£o otimizada do gradient boosting
5. ğŸ¯ **K-Nearest Neighbors Classifier** - KNN com otimizaÃ§Ã£o de vizinhos e mÃ©tricas de distÃ¢ncia
6. ğŸ§  **Multi-Layer Perceptron Classifier** - Rede neural com arquitetura flexÃ­vel
7. âš¡ **Support Vector Classifier** - SVM com diferentes kernels

## ğŸ› ï¸ DependÃªncias

- **Python 3.8+**
- **pandas**: ManipulaÃ§Ã£o de dados
- **numpy**: OperaÃ§Ãµes numÃ©ricas  
- **scikit-learn**: Modelos de ML
- **optuna**: OtimizaÃ§Ã£o de hiperparÃ¢metros
- **imblearn**: Balanceamento de classes (SMOTE)

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1ï¸âƒ£ ConfiguraÃ§Ã£o Inicial
```bash
cd /Users/i583975/git/tcc/artigo
python setup.py
```

**Ou manualmente:**

1. **Criar ambiente virtual:**
```bash
cd /Users/i583975/git/tcc
python3 -m venv mlenv
source mlenv/bin/activate
```

2. **Instalar dependÃªncias:**
```bash
pip install pandas numpy scikit-learn optuna imbalanced-learn
```

## ğŸ“‹ Dados NecessÃ¡rios

- ğŸ“„ **UNION_features.tsv**: Features multi-Ã´micas (CNA, GE, METH, MF)
- ğŸ·ï¸ **UNION_labels.tsv**: Labels de classificaÃ§Ã£o (True/False)

**LocalizaÃ§Ã£o:**
- Features: `/Users/i583975/git/tcc/renan/data_files/omics_features/UNION_features.tsv`
- Labels: `/Users/i583975/git/tcc/renan/data_files/labels/UNION_labels.tsv`

## ğŸš€ Como Usar

### 1ï¸âƒ£ Teste do Ambiente

```bash
cd /Users/i583975/git/tcc/artigo
python test_environment.py
```

### 2ï¸âƒ£ Exemplo Individual

```bash
python exemplo.py
```

### 3ï¸âƒ£ Experimento Completo

```bash
python main.py
```

### 4ï¸âƒ£ Uso ProgramÃ¡tico

```python
import sys
sys.path.append('/Users/i583975/git/tcc')

from processamento import prepare_dataset
from models import optimize_random_forest_classifier

# Preparar dados
X, y, gene_names, feature_names = prepare_dataset(
    "/Users/i583975/git/tcc/renan/data_files/omics_features/UNION_features.tsv",
    "/Users/i583975/git/tcc/renan/data_files/labels/UNION_labels.tsv"
)

# Executar Random Forest
best_model = optimize_random_forest_classifier(X, y, n_trials=50)
```

## ğŸ”„ Funcionalidades

### ğŸ“Š Processamento de Dados
- âœ… Carregamento automÃ¡tico de `UNION_features.tsv` e `UNION_labels.tsv`
- âœ… Alinhamento automÃ¡tico de features e labels por gene
- âœ… Tratamento de valores faltantes (preenchimento com 0)
- âœ… ConversÃ£o automÃ¡tica de labels (True/False â†’ 1/0)
- âœ… AnÃ¡lise exploratÃ³ria automÃ¡tica do dataset

### ğŸ›ï¸ OtimizaÃ§Ã£o de HiperparÃ¢metros
- âœ… **Optuna**: Framework para otimizaÃ§Ã£o bayesiana
- âœ… **ValidaÃ§Ã£o cruzada estratificada**: 5-fold (adaptativo para datasets pequenos)
- âœ… **Holdout 80/20**: DivisÃ£o para treino/validaÃ§Ã£o e teste final
- âœ… **ConfiguraÃ§Ã£o flexÃ­vel**: NÃºmero de trials personalizÃ¡vel

### ğŸ“ˆ AvaliaÃ§Ã£o Completa
- âœ… **MÃ©tricas**: AcurÃ¡cia, PrecisÃ£o, Recall, F1-Score
- âœ… **Classification Report**: RelatÃ³rio detalhado por classe
- âœ… **Pipelines**: IntegraÃ§Ã£o automÃ¡tica com StandardScaler
- âœ… **Tracking**: Tempo de execuÃ§Ã£o por trial e modelo

### ğŸ’¾ Sistema de Resultados
- âœ… **Salvamento automÃ¡tico** de resultados em arquivos organizados
- âœ… **Estrutura por modelo**: DiretÃ³rios separados para cada algoritmo
- âœ… **Formatos mÃºltiplos**: JSON (trials) + TXT (relatÃ³rios)
- âœ… **Timestamps**: Arquivos com data/hora para versionamento

## âš™ï¸ CaracterÃ­sticas da ImplementaÃ§Ã£o

### ğŸ¯ ValidaÃ§Ã£o Robusta
- **EstratificaÃ§Ã£o**: MantÃ©m proporÃ§Ã£o das classes em todas as divisÃµes
- **Holdout 80/20**: DivisÃ£o inicial para treino/validaÃ§Ã£o e teste
- **5-Fold Stratified CV**: ValidaÃ§Ã£o cruzada estratificada interna (adaptativo)
- **Cross-Validation**: Ajusta automaticamente o nÃºmero de folds para datasets pequenos

### ğŸ”§ OtimizaÃ§Ã£o AutomÃ¡tica
- **Optuna**: Framework para otimizaÃ§Ã£o bayesiana de hiperparÃ¢metros
- **Trials configurÃ¡veis**: NÃºmero de tentativas por modelo (padrÃ£o: 30)
- **MÃ©tricas**: AcurÃ¡cia como mÃ©trica principal de otimizaÃ§Ã£o
- **Sampling**: TPE (Tree-structured Parzen Estimator) para eficiÃªncia

### ğŸ“Š AvaliaÃ§Ã£o Completa
- **AcurÃ¡cia**: MÃ©trica principal para comparaÃ§Ã£o
- **PrecisÃ£o**: MÃ©dia ponderada por classe
- **Recall**: MÃ©dia ponderada por classe  
- **F1-Score**: MÃ©dia ponderada por classe
- **Classification Report**: RelatÃ³rio detalhado por classe

### ğŸ”„ PrÃ©-processamento
- **StandardScaler**: NormalizaÃ§Ã£o automÃ¡tica das features
- **Pipeline**: IntegraÃ§Ã£o transparente de preprocessamento e modelo
- **SMOTE**: TÃ©cnica de oversampling para balanceamento (quando necessÃ¡rio)

## ğŸ”¢ ConfiguraÃ§Ã£o dos HiperparÃ¢metros

Cada modelo tem ranges especÃ­ficos de hiperparÃ¢metros otimizados:

### ğŸŒ³ Decision Tree
- `max_depth`: 2-32
- `min_samples_split`: 2-20
- `min_samples_leaf`: 1-20
- `criterion`: gini, entropy

### ğŸŒ² Random Forest
- `n_estimators`: 100-300 (step 50)
- `max_depth`: 5-30
- `min_samples_split`: 2-20
- `min_samples_leaf`: 1-20
- `max_features`: sqrt, log2, None
- `criterion`: gini, entropy

### ğŸ“ˆ Gradient Boosting
- `n_estimators`: 100-300 (step 50)
- `learning_rate`: 0.01-0.3
- `max_depth`: 3-10
- `min_samples_split`: 2-20
- `min_samples_leaf`: 1-20
- `subsample`: 0.8-1.0

### ğŸ“Š Histogram Gradient Boosting
- `max_iter`: 50-200
- `learning_rate`: 0.01-0.3
- `max_depth`: 3-15
- `min_samples_leaf`: 1-50
- `l2_regularization`: 0.0-1.0

### ğŸ¯ K-Nearest Neighbors
- `n_neighbors`: 1-20
- `weights`: uniform, distance
- `algorithm`: auto, ball_tree, kd_tree, brute
- `p`: 1 (manhattan), 2 (euclidean)

### ğŸ§  Multi-Layer Perceptron
- `n_layers`: 1-3
- `layer_size`: 10-200 (por camada)
- `activation`: tanh, relu, logistic
- `alpha`: 1e-5 to 1e-1 (log scale)
- `learning_rate`: constant, invscaling, adaptive
- `max_iter`: 200-1000

### âš¡ Support Vector Classifier
- `kernel`: linear, poly, rbf, sigmoid
- `C`: 1e-3 to 1e3 (log scale)
- `gamma`: scale, auto (para kernels nÃ£o-lineares)
- `degree`: 2-5 (apenas para kernel poly)

## ğŸ“ˆ Output Esperado

O experimento produz:

### ğŸ“Š Logs Detalhados
- Progresso de cada trial de otimizaÃ§Ã£o
- Melhores hiperparÃ¢metros encontrados para cada modelo
- Tempo de execuÃ§Ã£o por trial e total
- AvaliaÃ§Ã£o completa no conjunto de teste

### ğŸ’¾ Arquivos de Resultados
- **`/results/{modelo}/trials_{timestamp}.json`**: HistÃ³rico completo de trials
- **`/results/{modelo}/test_results_{timestamp}.txt`**: RelatÃ³rio formatado dos resultados

### ğŸ“‹ Resumo Final
- Modelos bem-sucedidos vs com erro
- ComparaÃ§Ã£o de performance entre algoritmos
- DistribuiÃ§Ã£o final das classes no dataset

## ğŸ’¡ Exemplos de Uso

### ğŸ”¬ Modelo Individual
```python
from processamento import prepare_dataset
from models import optimize_random_forest_classifier

# Carregar dados
X, y, genes, features = prepare_dataset(features_path, labels_path)

# Otimizar Random Forest
best_model = optimize_random_forest_classifier(X, y, n_trials=50)
```

### ğŸ“Š ComparaÃ§Ã£o de Modelos
```python
# Ver exemplo completo em exemplo.py
python exemplo.py
```

### ğŸš€ Experimento Completo
```python
# Ver configuraÃ§Ã£o completa em main.py
python main.py
```

### ğŸ“ AnÃ¡lise de Resultados
```python
import json
import pandas as pd

# Carregar resultados de trials
with open('/results/random_forest/trials_20250820_123456.json', 'r') as f:
    trials_data = json.load(f)

# Converter para DataFrame para anÃ¡lise
trials_df = pd.DataFrame(trials_data)
print(f"Melhor trial: {trials_df.loc[trials_df['score'].idxmax()]}")
```

## ğŸ”§ PersonalizaÃ§Ã£o

### ğŸ›ï¸ Alterar NÃºmero de Trials
```python
# Edite a variÃ¡vel N_TRIALS no arquivo main.py (padrÃ£o: 30)
N_TRIALS = 50  # Para otimizaÃ§Ã£o mais demorada mas possivelmente melhor
```

### ğŸ“Š Modificar MÃ©trica de OtimizaÃ§Ã£o
```python
# Altere o parÃ¢metro scoring nas funÃ§Ãµes de otimizaÃ§Ã£o
score = cross_val_score(
    pipeline, X_trainval, y_trainval,
    cv=inner_cv,
    scoring="f1_weighted"  # PadrÃ£o: "accuracy"
).mean()
```

### â• Adicionar Novos Modelos
1. Implemente nova funÃ§Ã£o de otimizaÃ§Ã£o em `/Users/i583975/git/tcc/models.py`
2. Siga o padrÃ£o: `optimize_{nome}_classifier(X, y, n_trials=30, save_results=True)`
3. Adicione ao `models_config` em `main.py`

### ğŸ¯ Balanceamento de Classes
```python
# Para datasets muito desbalanceados, considere usar SMOTE
from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X_balanced, y_balanced = smote.fit_resample(X, y)
```

## ğŸ¯ PrÃ³ximos Passos

1. âœ… **Execute `setup.py`** para verificar ambiente
2. âœ… **Teste com `test_environment.py`** para validar instalaÃ§Ã£o
3. âœ… **Execute `exemplo.py`** para validar funcionamento
4. âœ… **Execute `main.py`** para experimento completo
5. ğŸ“Š **Analise resultados** na pasta `/results/`
6. ğŸ’¾ **Salve melhores modelos** para uso futuro

## ğŸš¨ Troubleshooting

### âŒ Erro de MÃ³dulo NÃ£o Encontrado
```bash
# Ativar ambiente virtual
source /Users/i583975/git/tcc/mlenv/bin/activate

# Instalar dependÃªncias faltantes
pip install pandas scikit-learn optuna imbalanced-learn
```

### ğŸ“ Arquivo de Dados NÃ£o Encontrado
Verifique se os caminhos dos arquivos estÃ£o corretos:
- `UNION_features.tsv`: Features multi-Ã´micas
- `UNION_labels.tsv`: Labels de classificaÃ§Ã£o

### ğŸ’¾ Problemas de MemÃ³ria
- Reduza o nÃºmero de trials (`N_TRIALS = 10`)
- Use menos folds na validaÃ§Ã£o cruzada (modifique `get_optimal_cv_folds`)
- Filtre features menos relevantes antes do treinamento

### âš ï¸ Dataset Desbalanceado
- O projeto jÃ¡ trata automaticamente datasets desbalanceados
- Classes minoritÃ¡rias sÃ£o preservadas na estratificaÃ§Ã£o
- Considere mÃ©tricas como F1-Score para datasets muito desbalanceados

### ğŸ› Erros de ConvergÃªncia (MLP/SVC)
- Aumente `max_iter` para MLP
- Reduza o range de `C` para SVC
- Use features normalizadas (jÃ¡ implementado via Pipeline)

## ğŸ’¾ Resultados e PersistÃªncia

### ğŸ”„ Salvamento AutomÃ¡tico
Os modelos treinados podem ser salvos e reutilizados:

```python
import joblib

# Salvar modelo apÃ³s otimizaÃ§Ã£o
joblib.dump(best_model, 'models/best_random_forest_model.pkl')

# Carregar modelo salvo
loaded_model = joblib.load('models/best_random_forest_model.pkl')

# Fazer prediÃ§Ãµes em novos dados
predictions = loaded_model.predict(new_data)
probabilities = loaded_model.predict_proba(new_data)
```

### ğŸ“Š AnÃ¡lise de Performance
```python
# Comparar resultados de mÃºltiplos modelos
import os
import json

results_dir = '/Users/i583975/git/tcc/artigo/results'
models_performance = {}

for model_name in os.listdir(results_dir):
    model_dir = os.path.join(results_dir, model_name)
    if os.path.isdir(model_dir):
        # Encontrar arquivo de resultados mais recente
        result_files = [f for f in os.listdir(model_dir) if f.startswith('test_results_')]
        if result_files:
            latest_file = sorted(result_files)[-1]
            # Extrair mÃ©tricas do arquivo
            models_performance[model_name] = latest_file

print("Performance dos modelos:", models_performance)
```

### ğŸ“ˆ VisualizaÃ§Ã£o de Resultados
```python
import matplotlib.pyplot as plt
import pandas as pd

# Exemplo de visualizaÃ§Ã£o de trials do Optuna
with open('results/random_forest/trials_latest.json', 'r') as f:
    trials = json.load(f)

df_trials = pd.DataFrame(trials)
plt.figure(figsize=(10, 6))
plt.plot(df_trials['trial_number'], df_trials['score'])
plt.title('EvoluÃ§Ã£o da Performance durante OtimizaÃ§Ã£o')
plt.xlabel('Trial Number')
plt.ylabel('Accuracy Score')
plt.show()
```

---

## ğŸ‰ Status do Projeto

**âœ… PROJETO PRONTO PARA USO!**

Todos os arquivos foram criados e estÃ£o funcionais. O sistema estÃ¡ configurado para classificaÃ§Ã£o de genes-alvo usando dados multi-Ã´micos com otimizaÃ§Ã£o automÃ¡tica de hiperparÃ¢metros.

### ğŸ“‹ Checklist de Funcionalidades

- [x] **Processamento de dados** multi-Ã´micos
- [x] **7 algoritmos de ML** implementados
- [x] **OtimizaÃ§Ã£o automÃ¡tica** com Optuna
- [x] **ValidaÃ§Ã£o robusta** com CV estratificada
- [x] **Sistema de resultados** organizados
- [x] **DocumentaÃ§Ã£o completa** e exemplos
- [x] **Tratamento de erros** e edge cases
- [x] **Pipeline automatizada** end-to-end

### ğŸš€ Capacidades do Sistema

- **Dataset suportado**: 13.825 genes com features multi-Ã´micas
- **Classes balanceadas**: Tratamento automÃ¡tico de desbalanceamento
- **Escalabilidade**: ConfiguraÃ§Ãµes adaptÃ¡veis ao tamanho do dataset
- **Reprodutibilidade**: Seeds fixadas para resultados consistentes
- **Monitoramento**: Logs detalhados e tracking de performance

---

**Desenvolvido para classificaÃ§Ã£o de oncogenes usando dados multi-Ã´micos integrados** ğŸ§¬
