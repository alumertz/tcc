#!/usr/bin/env python3
"""
Arquivo principal para experimenta√ß√£o com modelos de classifica√ß√£o
para predi√ß√£o de genes-alvo usando dados √¥micos.
"""

import sys
import os
import argparse
sys.path.append('/Users/i583975/git/tcc')

import numpy as np
import pandas as pd
from src.processing import prepare_dataset, get_dataset_info
from src.models import (
    optimize_decision_tree_classifier,
    optimize_random_forest_classifier,
    optimize_gradient_boosting_classifier,
    optimize_hist_gradient_boosting_classifier,
    optimize_knn_classifier,
    optimize_mlp_classifier,
    optimize_svc_classifier,
    optimize_catboost_classifier,
    optimize_xgboost_classifier
)
from src.reports import summarize_results
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.svm import SVC
from catboost import CatBoostClassifier
from xgboost import XGBClassifier
from evaluation import evaluate_model_default
import warnings
warnings.filterwarnings('ignore')

def get_data_paths(use_renan=False):
    """
    Retorna os caminhos dos arquivos baseado na fonte de dados escolhida
    
    Args:
        use_renan (bool): Se True, usa arquivos do Renan; se False, usa arquivos da Ana
        
    Returns:
        tuple: (features_path, labels_path, data_source)
    """
    if use_renan:
        features_path = "./renan/data_files/omics_features/UNION_features.tsv"
        labels_path = "./renan/data_files/labels/UNION_labels.tsv"
        data_source = "RENAN"
        print(f"üìÅ Usando dados do RENAN:")
        print(f"   Features: renan/data_files/omics_features/UNION_features.tsv")
        print(f"   Labels: renan/data_files/labels/UNION_labels.tsv")
        print(f"   Formato labels: gene, label (True/False/NaN)")
    else:
        features_path = "./data/UNION_features.tsv"
        labels_path = "./data/processed/UNION_labels.tsv"
        data_source = "ANA"
        print(f"üìÅ Usando dados da ANA:")
        print(f"   Features: data/UNION_features.tsv")
        print(f"   Labels: data/processed/UNION_labels.tsv") 
        print(f"   Formato labels: genes, 2class (binary), 3class (multiclass)")
    print()
    
    return features_path, labels_path, data_source

def parse_arguments():
    """
    Processa argumentos da linha de comando
    
    Returns:
        argparse.Namespace: Argumentos processados
    """
    parser = argparse.ArgumentParser(
        description='Experimenta√ß√£o com modelos de classifica√ß√£o para predi√ß√£o de genes-alvo',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos de uso:
  python main.py                    # Modelos otimizados, dados Ana, classifica√ß√£o bin√°ria
  python main.py -default           # Modelos com par√¢metros padr√£o (r√°pido)
  python main.py -renan             # Usa arquivos do Renan (formato original)
  python main.py -multiclass        # Classifica√ß√£o multiclasse (TSG vs Oncogene vs Passenger)
  python main.py -default -multiclass # Par√¢metros padr√£o + multiclasse
  python main.py --help             # Mostra esta ajuda
        """
    )
    
    parser.add_argument(
        '-renan', '--renan', 
        action='store_true',
        help='Usa arquivos de dados do Renan (formato original: gene, label)'
    )
    
    parser.add_argument(
        '-multiclass', '--multiclass',
        action='store_true',
        help='Usa classifica√ß√£o multiclasse (TSG=1, Oncogene=2) ao inv√©s de bin√°ria (cancer=1)'
    )
    
    parser.add_argument(
        '-default', '--default',
        action='store_true',
        help='Executa modelos com par√¢metros padr√£o (sem otimiza√ß√£o Optuna)'
    )
    
    return parser.parse_args()

def run_single_model_optimize(model_name, optimizer_func, X, y, n_trials=10, data_source="ana", classification_type="binary"):
    """
    Executa um √∫nico modelo de classifica√ß√£o
    
    Args:
        model_name (str): Nome do modelo
        optimizer_func (function): Fun√ß√£o de otimiza√ß√£o do modelo
        X (np.array): Features
        y (np.array): Labels
        n_trials (int): N√∫mero de trials para otimiza√ß√£o
        data_source (str): "ana" ou "renan"
        classification_type (str): "binary" ou "multiclass"
        
    Returns:
        dict: Resultados do modelo
    """
    print("="*80)
    print(f"EXECUTANDO MODELO: {model_name}")
    print("="*80)
    
    try:
        # Executa otimiza√ß√£o (com salvamento autom√°tico)
        best_model, test_metrics = optimizer_func(X, y, n_trials=n_trials, save_results=True, 
                                                data_source=data_source, classification_type=classification_type,
                                                use_nested_cv=True, outer_cv_folds=5)
        
        results = {
            'model_name': model_name,
            'status': 'success',
            'model': best_model,
            'test_metrics': test_metrics
        }
        
        print(f"‚úì {model_name} executado com sucesso!")
        return results
        
    except Exception as e:
        print(f"‚úó Erro ao executar {model_name}: {e}")
        return {
            'model_name': model_name,
            'status': 'error',
            'error': str(e),
            'model': None
        }

def run_all_models_optimize(X, y, n_trials=10, data_source="ana", classification_type="binary"):
    """
    Executa todos os modelos de classifica√ß√£o
    
    Args:
        X (np.array): Features
        y (np.array): Labels
        n_trials (int): N√∫mero de trials para otimiza√ß√£o
        data_source (str): "ana" ou "renan"
        classification_type (str): "binary" ou "multiclass"
        
    Returns:
        list: Lista com resultados de todos os modelos
    """
    # Defini√ß√£o dos modelos e suas fun√ß√µes de otimiza√ß√£o
    models_config = [
        ("Decision Tree", optimize_decision_tree_classifier),
        ("Random Forest", optimize_random_forest_classifier),
        ("Gradient Boosting", optimize_gradient_boosting_classifier),
        ("Histogram Gradient Boosting", optimize_hist_gradient_boosting_classifier),
        ("K-Nearest Neighbors", optimize_knn_classifier),
        ("Multi-Layer Perceptron", optimize_mlp_classifier),
        ("Support Vector Classifier", optimize_svc_classifier),
        ("CatBoost", optimize_catboost_classifier),
        ("XGBoost", optimize_xgboost_classifier)
    ]
    
    results = []
    
    print("INICIANDO EXPERIMENTA√á√ÉO COM TODOS OS MODELOS")
    print(f"Dataset: {X.shape[0]} amostras x {X.shape[1]} features")
    print(f"N√∫mero de trials por modelo: {n_trials}")
    print()
    
    for i, (model_name, optimizer_func) in enumerate(models_config, 1):
        print(f"Progresso: {i}/{len(models_config)} modelos")
        
        result = run_single_model_optimize(model_name, optimizer_func, X, y, n_trials, data_source, classification_type)
        results.append(result)
        
        # Breve pausa entre modelos
        import time
        time.sleep(2)
    
    return results

def run_all_default_models(X, y, data_source="ana", classification_type="binary"):
    """
    Executa todos os modelos com par√¢metros padr√£o
    Pipeline unificado para todos: StandardScaler + Classifier
    
    Args:
        X (np.array): Features
        y (np.array): Labels
        data_source (str): "ana" ou "renan"
        classification_type (str): "binary" ou "multiclass"
        
    Returns:
        list: Lista com resultados de todos os modelos
    """
    # Modelos com par√¢metros padr√£o (mesma lista do main_default_models.py)
    default_models = [
        ("Decision Tree", DecisionTreeClassifier(random_state=42)),
        ("Random Forest", RandomForestClassifier(random_state=42)),
        ("Gradient Boosting", GradientBoostingClassifier(random_state=42)),
        ("Histogram Gradient Boosting", HistGradientBoostingClassifier(random_state=42)),
        ("K-Nearest Neighbors", KNeighborsClassifier()),
        ("Multi-Layer Perceptron", MLPClassifier(random_state=42, max_iter=1000)),
        ("Support Vector Classifier", SVC(probability=True, random_state=42)),
        ("CatBoost", CatBoostClassifier(random_state=42, verbose=False)),
        ("XGBoost", XGBClassifier(random_state=42, verbosity=0, eval_metric='logloss'))
    ]
    
    results = []
    
    print("INICIANDO AVALIA√á√ÉO COM PAR√ÇMETROS PADR√ÉO")
    print(f"Dataset: {X.shape[0]} amostras x {X.shape[1]} features")
    print(f"Pipeline: StandardScaler + Classifier (unificado)")
    print(f"M√©tricas: Binary (precision, recall, f1)")
    print()
    
    for i, (model_name, model) in enumerate(default_models, 1):
        print(f"\nProgresso: {i}/{len(default_models)} modelos")
        
        try:
            result = evaluate_model_default(model, model_name, X, y, data_source, classification_type)
            results.append(result)
            print(f"‚úì {model_name} executado com sucesso!")
            
        except Exception as e:
            print(f"‚úó Erro ao executar {model_name}: {e}")
            results.append({
                'model_name': model_name,
                'status': 'error',
                'error': str(e)
            })
    
    return results

def main(use_renan=False, use_multiclass=False, use_default=False):
    """
    Fun√ß√£o principal do experimento
    
    Args:
        use_renan (bool): Se True, usa arquivos do Renan; se False, usa arquivos da Ana
        use_multiclass (bool): Se True, usa classifica√ß√£o multiclasse; se False, usa bin√°ria
        use_default (bool): Se True, usa par√¢metros padr√£o; se False, otimiza com Optuna
    """
    print("CLASSIFICA√á√ÉO DE GENES-ALVO USANDO DADOS √îMICOS")
    print("="*80)
    
    # Inicializar timestamp do experimento para toda a sess√£o
    from src.reports import set_experiment_timestamp
    experiment_timestamp = set_experiment_timestamp()
    print(f"üïê Timestamp do experimento: {experiment_timestamp}")
    print()
    
    # Obt√©m os caminhos dos arquivos baseado na fonte escolhida
    features_path, labels_path, data_source = get_data_paths(use_renan)
    
    # Verifica se os arquivos existem
    if not os.path.exists(features_path):
        print(f"‚ùå Arquivo de features n√£o encontrado: {features_path}")
        return
    
    if not os.path.exists(labels_path):
        print(f"‚ùå Arquivo de labels n√£o encontrado: {labels_path}")
        return
    
    print("‚úÖ Arquivos encontrados com sucesso!")
    
    # Prepara o dataset
    print("üîÑ Carregando e preparando dados...")
    classification_type = 'multiclass' if use_multiclass else 'binary'
    X, y, gene_names, feature_names = prepare_dataset(features_path, labels_path, classification_type)
    
    if X is None:
        print("‚ùå Erro ao preparar dataset. Abortando.")
        return
    
    # Mostra informa√ß√µes do dataset
    dataset_info = get_dataset_info(X, y, gene_names, feature_names)
    print("\nüìä INFORMA√á√ïES DO DATASET:")
    print(f"  Fonte de dados: {data_source}")
    print(f"  Amostras: {dataset_info['n_samples']}")
    print(f"  Features: {dataset_info['n_features']}")
    print(f"  Distribui√ß√£o das classes: {dataset_info['class_distribution']}")
    print(f"  Estat√≠sticas das features:")
    print(f"    - M√©dia: {dataset_info['feature_stats']['mean']:.4f}")
    print(f"    - Desvio padr√£o: {dataset_info['feature_stats']['std']:.4f}")
    print(f"    - Valores zero: {dataset_info['feature_stats']['zeros_percentage']:.2f}%")
    
    # Configura√ß√£o do experimento baseado no modo escolhido
    if use_default:
        print(f"\n‚öôÔ∏è  CONFIGURA√á√ÉO DO EXPERIMENTO (PAR√ÇMETROS PADR√ÉO):")
        print(f"  Modo: Par√¢metros padr√£o do scikit-learn")
        print(f"  Pipeline: StandardScaler + Classifier (unificado)")
        print(f"  M√©tricas: Binary (precision, recall, f1)")
        print(f"  Valida√ß√£o: Estratificada 5-fold + Holdout 80/20")
        print(f"  Tempo estimado: ~2-5 minutos")
        print(f"  Resultados salvos em: /Users/i583975/git/tcc/results/")
        print()
        
        # Executa modelos com par√¢metros padr√£o
        print("üöÄ Iniciando experimentos com par√¢metros padr√£o...")
        data_source = "renan" if use_renan else "ana"
        classification_type = "multiclass" if use_multiclass else "binary"
        results = run_all_default_models(X, y, data_source, classification_type)
        
    else:
        N_TRIALS = 30  # N√∫mero de trials por modelo
        print(f"\n‚öôÔ∏è  CONFIGURA√á√ÉO DO EXPERIMENTO (OTIMIZA√á√ÉO):")
        print(f"  Modo: Otimiza√ß√£o com Optuna")
        print(f"  Trials por modelo: {N_TRIALS}")
        print(f"  Pipeline: StandardScaler + Classifier (unificado)")
        print(f"  M√©tricas: Binary (precision, recall, f1)")
        print(f"  Valida√ß√£o: Estratificada 5-fold + Holdout 80/20")
        print(f"  M√©trica de otimiza√ß√£o: PR AUC (Average Precision)")
        print(f"  Tempo estimado: ~30 minutos por modelo")
        print(f"  Resultados salvos em: /Users/i583975/git/tcc/results/")
        print()
        
        # Executa todos os modelos com otimiza√ß√£o
        print("üöÄ Iniciando experimentos com otimiza√ß√£o...")
        results = run_all_models_optimize(X, y, n_trials=N_TRIALS, data_source=data_source, classification_type=classification_type)
    #results = run_single_model("Gradient Boosting", optimize_gradient_boosting_classifier, X, y, n_trials=N_TRIALS)
    #results = run_single_model("Decision Tree", optimize_decision_tree_classifier, X, y, n_trials=N_TRIALS)
    #results = run_single_model("Support Vector Classifier", optimize_svc_classifier, X, y, n_trials=N_TRIALS)
    #results = run_single_model("Multi-Layer Perceptron", optimize_mlp_classifier, X, y, n_trials=N_TRIALS)
    #results = run_single_model("CatBoost", optimize_catboost_classifier, X, y, n_trials=N_TRIALS)

    # Resumo final
    data_source = "renan" if use_renan else "ana"
    classification_type = "multiclass" if use_multiclass else "binary"
    
    if use_default:
        summarize_results(results, mode="default", data_source=data_source, 
                        classification_type=classification_type)
    else:
        summarize_results(results, mode="optimized", data_source=data_source,
                        classification_type=classification_type)
    
    print("\nüéâ EXPERIMENTO CONCLU√çDO!")
    print("üíæ Resultados salvos em arquivos organizados por modelo.")


if __name__ == "__main__":
    # Processa argumentos da linha de comando
    args = parse_arguments()
    
    # Executa o experimento com as op√ß√µes escolhidas
    main(args.renan, args.multiclass, args.default)
